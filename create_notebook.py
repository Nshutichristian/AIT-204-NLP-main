{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f138b2-a4c3-4055-9f28-63021783bcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Notebook created: sentiment_analysis.ipynb\n",
      "\n",
      "üìñ To open in browser:\n",
      "   jupyter notebook sentiment_analysis.ipynb\n",
      "\n",
      "   or\n",
      "   jupyter lab sentiment_analysis.ipynb\n",
      "\n",
      "üåê Your browser will open automatically!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create Sentiment Analysis Jupyter Notebook\n",
    "Run this script to generate sentiment_analysis.ipynb\n",
    "Then open it in your browser with: jupyter notebook sentiment_analysis.ipynb\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "def create_notebook():\n",
    "    \"\"\"Generate the complete Jupyter notebook\"\"\"\n",
    "    \n",
    "    notebook = {\n",
    "        \"cells\": [\n",
    "            # Cell 1: Title\n",
    "            {\n",
    "                \"cell_type\": \"markdown\",\n",
    "                \"metadata\": {},\n",
    "                \"source\": [\n",
    "                    \"# Sentiment Analysis using NLTK and Machine Learning\\n\",\n",
    "                    \"## Technical Report - Jupyter Notebook\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"**Author:** Data Analytics Student  \\n\",\n",
    "                    \"**Date:** October 2025  \\n\",\n",
    "                    \"**Project:** Text Sentiment Analysis using Natural Language Processing\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"---\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"## Instructions\\n\",\n",
    "                    \"- Run cells in order with **Shift+Enter**\\n\",\n",
    "                    \"- Or click **Cell ‚Üí Run All** to execute everything\\n\",\n",
    "                    \"- Estimated time: 5-10 minutes\"\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # Cell 2: Problem Statement\n",
    "            {\n",
    "                \"cell_type\": \"markdown\",\n",
    "                \"metadata\": {},\n",
    "                \"source\": [\n",
    "                    \"## 1. Problem Statement\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"### Objectives:\\n\",\n",
    "                    \"1. Analyze sentiment (positive, negative, neutral) in text data\\n\",\n",
    "                    \"2. Build a machine learning model to classify sentiment\\n\",\n",
    "                    \"3. Evaluate model performance\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"### Technical Goal:\\n\",\n",
    "                    \"Develop a classification model using TF-IDF vectorization and logistic regression.\"\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # Cell 3: Import Libraries\n",
    "            {\n",
    "                \"cell_type\": \"code\",\n",
    "                \"execution_count\": None,\n",
    "                \"metadata\": {},\n",
    "                \"outputs\": [],\n",
    "                \"source\": [\n",
    "                    \"# Import required libraries\\n\",\n",
    "                    \"import numpy as np\\n\",\n",
    "                    \"import pandas as pd\\n\",\n",
    "                    \"import warnings\\n\",\n",
    "                    \"warnings.filterwarnings('ignore')\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Visualization\\n\",\n",
    "                    \"import matplotlib.pyplot as plt\\n\",\n",
    "                    \"import seaborn as sns\\n\",\n",
    "                    \"plt.style.use('seaborn-v0_8-darkgrid')\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Text processing\\n\",\n",
    "                    \"from bs4 import BeautifulSoup\\n\",\n",
    "                    \"import re\\n\",\n",
    "                    \"import string\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# NLTK\\n\",\n",
    "                    \"import nltk\\n\",\n",
    "                    \"from nltk.corpus import stopwords\\n\",\n",
    "                    \"from nltk.tokenize import word_tokenize\\n\",\n",
    "                    \"from nltk.stem import WordNetLemmatizer\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Machine Learning\\n\",\n",
    "                    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "                    \"from sklearn.feature_extraction.text import TfidfVectorizer\\n\",\n",
    "                    \"from sklearn.linear_model import LogisticRegression\\n\",\n",
    "                    \"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Download NLTK data\\n\",\n",
    "                    \"nltk.download('stopwords', quiet=True)\\n\",\n",
    "                    \"nltk.download('punkt', quiet=True)\\n\",\n",
    "                    \"nltk.download('wordnet', quiet=True)\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"print('‚úÖ Libraries imported successfully!')\"\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # Cell 4: Load Data\n",
    "            {\n",
    "                \"cell_type\": \"code\",\n",
    "                \"execution_count\": None,\n",
    "                \"metadata\": {},\n",
    "                \"outputs\": [],\n",
    "                \"source\": [\n",
    "                    \"# Create sample dataset\\n\",\n",
    "                    \"np.random.seed(42)\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Positive reviews\\n\",\n",
    "                    \"positive_reviews = [\\n\",\n",
    "                    \"    \\\"This product is amazing! Exceeded all my expectations.\\\",\\n\",\n",
    "                    \"    \\\"Absolutely love it! Best purchase I've made this year.\\\",\\n\",\n",
    "                    \"    \\\"Excellent quality and fast shipping. Highly recommend!\\\",\\n\",\n",
    "                    \"    \\\"Perfect! Exactly what I was looking for.\\\",\\n\",\n",
    "                    \"    \\\"Outstanding product. Worth every penny!\\\",\\n\",\n",
    "                    \"] * 100\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Negative reviews\\n\",\n",
    "                    \"negative_reviews = [\\n\",\n",
    "                    \"    \\\"Terrible product. Complete waste of money.\\\",\\n\",\n",
    "                    \"    \\\"Very disappointed. Does not work as advertised.\\\",\\n\",\n",
    "                    \"    \\\"Poor quality. Broke after one use.\\\",\\n\",\n",
    "                    \"    \\\"Awful! Do not buy this product.\\\",\\n\",\n",
    "                    \"    \\\"Worst purchase ever. Requesting a refund.\\\",\\n\",\n",
    "                    \"] * 100\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Neutral reviews\\n\",\n",
    "                    \"neutral_reviews = [\\n\",\n",
    "                    \"    \\\"It's okay. Nothing special but does the job.\\\",\\n\",\n",
    "                    \"    \\\"Average product. Met basic expectations.\\\",\\n\",\n",
    "                    \"    \\\"It's fine. Not great, not terrible.\\\",\\n\",\n",
    "                    \"] * 100\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Create DataFrame\\n\",\n",
    "                    \"reviews = positive_reviews + negative_reviews + neutral_reviews\\n\",\n",
    "                    \"sentiments = (['positive'] * len(positive_reviews) + \\n\",\n",
    "                    \"              ['negative'] * len(negative_reviews) + \\n\",\n",
    "                    \"              ['neutral'] * len(neutral_reviews))\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"df = pd.DataFrame({\\n\",\n",
    "                    \"    'text': reviews,\\n\",\n",
    "                    \"    'sentiment': sentiments,\\n\",\n",
    "                    \"    'rating': np.random.choice([1, 2, 3, 4, 5], size=len(reviews))\\n\",\n",
    "                    \"})\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Add missing values\\n\",\n",
    "                    \"missing_indices = np.random.choice(df.index, size=int(0.05 * len(df)), replace=False)\\n\",\n",
    "                    \"df.loc[missing_indices, 'text'] = np.nan\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Shuffle\\n\",\n",
    "                    \"df = df.sample(frac=1, random_state=42).reset_index(drop=True)\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"print(f'‚úÖ Dataset created: {df.shape}')\\n\",\n",
    "                    \"df.head(10)\"\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # Cell 5: EDA\n",
    "            {\n",
    "                \"cell_type\": \"code\",\n",
    "                \"execution_count\": None,\n",
    "                \"metadata\": {},\n",
    "                \"outputs\": [],\n",
    "                \"source\": [\n",
    "                    \"# Exploratory Data Analysis\\n\",\n",
    "                    \"print('='*80)\\n\",\n",
    "                    \"print('EXPLORATORY DATA ANALYSIS')\\n\",\n",
    "                    \"print('='*80)\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"print('\\\\nDataset Info:')\\n\",\n",
    "                    \"print(df.info())\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"print('\\\\nMissing Values:')\\n\",\n",
    "                    \"print(df.isnull().sum())\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"print('\\\\nSentiment Distribution:')\\n\",\n",
    "                    \"print(df['sentiment'].value_counts())\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Handle missing values\\n\",\n",
    "                    \"df_clean = df.dropna(subset=['text']).copy()\\n\",\n",
    "                    \"print(f'\\\\n‚úÖ Clean dataset: {len(df_clean)} rows')\"\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # Cell 6: Visualization\n",
    "            {\n",
    "                \"cell_type\": \"code\",\n",
    "                \"execution_count\": None,\n",
    "                \"metadata\": {},\n",
    "                \"outputs\": [],\n",
    "                \"source\": [\n",
    "                    \"# Visualize sentiment distribution\\n\",\n",
    "                    \"fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Bar plot\\n\",\n",
    "                    \"df_clean['sentiment'].value_counts().plot(kind='bar', ax=axes[0], color=['green', 'red', 'gray'])\\n\",\n",
    "                    \"axes[0].set_title('Sentiment Distribution', fontsize=14, fontweight='bold')\\n\",\n",
    "                    \"axes[0].set_xlabel('Sentiment')\\n\",\n",
    "                    \"axes[0].set_ylabel('Count')\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Pie chart\\n\",\n",
    "                    \"df_clean['sentiment'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%')\\n\",\n",
    "                    \"axes[1].set_title('Sentiment Proportion', fontsize=14, fontweight='bold')\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"plt.tight_layout()\\n\",\n",
    "                    \"plt.show()\"\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # Cell 7: Text Preprocessing\n",
    "            {\n",
    "                \"cell_type\": \"code\",\n",
    "                \"execution_count\": None,\n",
    "                \"metadata\": {},\n",
    "                \"outputs\": [],\n",
    "                \"source\": [\n",
    "                    \"# Text preprocessing function\\n\",\n",
    "                    \"stop_words = set(stopwords.words('english'))\\n\",\n",
    "                    \"lemmatizer = WordNetLemmatizer()\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"def preprocess_text(text):\\n\",\n",
    "                    \"    if pd.isna(text):\\n\",\n",
    "                    \"        return ''\\n\",\n",
    "                    \"    \\n\",\n",
    "                    \"    # Remove HTML tags\\n\",\n",
    "                    \"    text = BeautifulSoup(text, 'html.parser').get_text()\\n\",\n",
    "                    \"    \\n\",\n",
    "                    \"    # Lowercase\\n\",\n",
    "                    \"    text = text.lower()\\n\",\n",
    "                    \"    \\n\",\n",
    "                    \"    # Remove URLs\\n\",\n",
    "                    \"    text = re.sub(r'http\\\\S+|www\\\\S+|https\\\\S+', '', text)\\n\",\n",
    "                    \"    \\n\",\n",
    "                    \"    # Remove punctuation\\n\",\n",
    "                    \"    text = text.translate(str.maketrans('', '', string.punctuation))\\n\",\n",
    "                    \"    \\n\",\n",
    "                    \"    # Remove numbers\\n\",\n",
    "                    \"    text = re.sub(r'\\\\d+', '', text)\\n\",\n",
    "                    \"    \\n\",\n",
    "                    \"    # Tokenize\\n\",\n",
    "                    \"    tokens = word_tokenize(text)\\n\",\n",
    "                    \"    \\n\",\n",
    "                    \"    # Remove stop words and lemmatize\\n\",\n",
    "                    \"    tokens = [lemmatizer.lemmatize(word) for word in tokens \\n\",\n",
    "                    \"              if word not in stop_words and len(word) > 2]\\n\",\n",
    "                    \"    \\n\",\n",
    "                    \"    return ' '.join(tokens)\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Apply preprocessing\\n\",\n",
    "                    \"print('Preprocessing text...')\\n\",\n",
    "                    \"df_clean['cleaned_text'] = df_clean['text'].apply(preprocess_text)\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Remove empty texts\\n\",\n",
    "                    \"df_clean = df_clean[df_clean['cleaned_text'].str.len() > 0].copy()\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"print(f'‚úÖ Preprocessing complete: {len(df_clean)} rows')\\n\",\n",
    "                    \"print('\\\\nSample:')\\n\",\n",
    "                    \"print(df_clean[['text', 'cleaned_text', 'sentiment']].head(3))\"\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # Cell 8: TF-IDF\n",
    "            {\n",
    "                \"cell_type\": \"code\",\n",
    "                \"execution_count\": None,\n",
    "                \"metadata\": {},\n",
    "                \"outputs\": [],\n",
    "                \"source\": [\n",
    "                    \"# TF-IDF Vectorization\\n\",\n",
    "                    \"X = df_clean['cleaned_text']\\n\",\n",
    "                    \"y = df_clean['sentiment']\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"tfidf_vectorizer = TfidfVectorizer(\\n\",\n",
    "                    \"    max_features=5000,\\n\",\n",
    "                    \"    min_df=2,\\n\",\n",
    "                    \"    max_df=0.8,\\n\",\n",
    "                    \"    ngram_range=(1, 2)\\n\",\n",
    "                    \")\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"X_tfidf = tfidf_vectorizer.fit_transform(X)\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"print(f'‚úÖ TF-IDF Matrix Shape: {X_tfidf.shape}')\\n\",\n",
    "                    \"print(f'Number of features: {len(tfidf_vectorizer.get_feature_names_out())}')\"\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # Cell 9: Train Model\n",
    "            {\n",
    "                \"cell_type\": \"code\",\n",
    "                \"execution_count\": None,\n",
    "                \"metadata\": {},\n",
    "                \"outputs\": [],\n",
    "                \"source\": [\n",
    "                    \"# Split data\\n\",\n",
    "                    \"X_train, X_test, y_train, y_test = train_test_split(\\n\",\n",
    "                    \"    X_tfidf, y, test_size=0.2, random_state=42, stratify=y\\n\",\n",
    "                    \")\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"print(f'Training set: {X_train.shape[0]} samples')\\n\",\n",
    "                    \"print(f'Testing set: {X_test.shape[0]} samples')\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Train model\\n\",\n",
    "                    \"print('\\\\nTraining Logistic Regression model...')\\n\",\n",
    "                    \"model = LogisticRegression(max_iter=1000, random_state=42)\\n\",\n",
    "                    \"model.fit(X_train, y_train)\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Evaluate\\n\",\n",
    "                    \"train_accuracy = model.score(X_train, y_train)\\n\",\n",
    "                    \"test_accuracy = model.score(X_test, y_test)\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"print(f'\\\\n‚úÖ Training Accuracy: {train_accuracy:.2%}')\\n\",\n",
    "                    \"print(f'‚úÖ Testing Accuracy: {test_accuracy:.2%}')\"\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # Cell 10: Predictions\n",
    "            {\n",
    "                \"cell_type\": \"code\",\n",
    "                \"execution_count\": None,\n",
    "                \"metadata\": {},\n",
    "                \"outputs\": [],\n",
    "                \"source\": [\n",
    "                    \"# Test predictions\\n\",\n",
    "                    \"test_sentences = [\\n\",\n",
    "                    \"    \\\"This is absolutely wonderful! I love it so much!\\\",\\n\",\n",
    "                    \"    \\\"Terrible experience. Would not recommend.\\\",\\n\",\n",
    "                    \"    \\\"It's okay, nothing special.\\\",\\n\",\n",
    "                    \"]\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"print('Making predictions on new text:\\\\n')\\n\",\n",
    "                    \"for i, sentence in enumerate(test_sentences, 1):\\n\",\n",
    "                    \"    cleaned = preprocess_text(sentence)\\n\",\n",
    "                    \"    transformed = tfidf_vectorizer.transform([cleaned])\\n\",\n",
    "                    \"    prediction = model.predict(transformed)[0]\\n\",\n",
    "                    \"    probabilities = model.predict_proba(transformed)[0]\\n\",\n",
    "                    \"    \\n\",\n",
    "                    \"    print(f'{i}. Text: {sentence}')\\n\",\n",
    "                    \"    print(f'   Predicted: {prediction.upper()}')\\n\",\n",
    "                    \"    print(f'   Confidence: {probabilities.max():.2%}\\\\n')\"\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # Cell 11: Confusion Matrix\n",
    "            {\n",
    "                \"cell_type\": \"code\",\n",
    "                \"execution_count\": None,\n",
    "                \"metadata\": {},\n",
    "                \"outputs\": [],\n",
    "                \"source\": [\n",
    "                    \"# Confusion matrix\\n\",\n",
    "                    \"y_pred = model.predict(X_test)\\n\",\n",
    "                    \"cm = confusion_matrix(y_test, y_pred)\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"plt.figure(figsize=(10, 8))\\n\",\n",
    "                    \"sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\\n\",\n",
    "                    \"            xticklabels=model.classes_,\\n\",\n",
    "                    \"            yticklabels=model.classes_)\\n\",\n",
    "                    \"plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\\n\",\n",
    "                    \"plt.ylabel('True Label')\\n\",\n",
    "                    \"plt.xlabel('Predicted Label')\\n\",\n",
    "                    \"plt.show()\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"# Classification report\\n\",\n",
    "                    \"print('\\\\nClassification Report:')\\n\",\n",
    "                    \"print(classification_report(y_test, y_pred))\"\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # Cell 12: Analysis\n",
    "            {\n",
    "                \"cell_type\": \"markdown\",\n",
    "                \"metadata\": {},\n",
    "                \"source\": [\n",
    "                    \"## Analysis of Findings\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"### Key Results:\\n\",\n",
    "                    \"- The model successfully classifies sentiment with high accuracy\\n\",\n",
    "                    \"- TF-IDF effectively captures important sentiment-bearing words\\n\",\n",
    "                    \"- Logistic regression provides interpretable results\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"### Strengths:\\n\",\n",
    "                    \"- Fast training and prediction\\n\",\n",
    "                    \"- Interpretable feature importance\\n\",\n",
    "                    \"- Good performance on clear sentiment\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"### Limitations:\\n\",\n",
    "                    \"- May struggle with sarcasm\\n\",\n",
    "                    \"- Limited context understanding\\n\",\n",
    "                    \"- Depends on training data quality\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"### Recommendations:\\n\",\n",
    "                    \"1. Increase dataset size and diversity\\n\",\n",
    "                    \"2. Try ensemble methods\\n\",\n",
    "                    \"3. Experiment with word embeddings\\n\",\n",
    "                    \"4. Consider deep learning for complex cases\"\n",
    "                ]\n",
    "            },\n",
    "            \n",
    "            # Cell 13: References\n",
    "            {\n",
    "                \"cell_type\": \"markdown\",\n",
    "                \"metadata\": {},\n",
    "                \"source\": [\n",
    "                    \"## References\\n\",\n",
    "                    \"\\n\",\n",
    "                    \"1. Bird, S., Klein, E., & Loper, E. (2009). Natural Language Processing with Python. O'Reilly.\\n\",\n",
    "                    \"2. Pedregosa, F., et al. (2011). Scikit-learn: Machine Learning in Python. JMLR.\\n\",\n",
    "                    \"3. Liu, B. (2012). Sentiment Analysis and Opinion Mining. Morgan & Claypool.\\n\",\n",
    "                    \"4. Manning, C. D., et al. (2008). Introduction to Information Retrieval. Cambridge.\\n\",\n",
    "                    \"5. NLTK Documentation: https://www.nltk.org/\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"metadata\": {\n",
    "            \"kernelspec\": {\n",
    "                \"display_name\": \"Python 3\",\n",
    "                \"language\": \"python\",\n",
    "                \"name\": \"python3\"\n",
    "            },\n",
    "            \"language_info\": {\n",
    "                \"name\": \"python\",\n",
    "                \"version\": \"3.8.0\"\n",
    "            }\n",
    "        },\n",
    "        \"nbformat\": 4,\n",
    "        \"nbformat_minor\": 4\n",
    "    }\n",
    "    \n",
    "    # Save the notebook\n",
    "    output_file = 'sentiment_analysis.ipynb'\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(notebook, f, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Notebook created: {output_file}\")\n",
    "    print(f\"\\nüìñ To open in browser:\")\n",
    "    print(f\"   jupyter notebook {output_file}\")\n",
    "    print(f\"\\n   or\")\n",
    "    print(f\"   jupyter lab {output_file}\")\n",
    "    print(f\"\\nüåê Your browser will open automatically!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67298c18-6431-4e75-9b25-573d20bcb538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
